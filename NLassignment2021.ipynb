{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLassignment2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMuskrat/Sentiment-Classification/blob/master/NLassignment2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk8JTP88A8vs",
        "outputId": "c68737b5-b7b3-4632-dea0-dbb889c25f06"
      },
      "source": [
        "#do not change the code in this cell\n",
        "#preliminary imports\n",
        "\n",
        "#set up nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "#for setting up training and testing data\n",
        "import random\n",
        "\n",
        "#useful other tools\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from itertools import zip_longest\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.classify.api import ClassifierI\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHBkzAccCVaZ"
      },
      "source": [
        "#do not change the code in this cell\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given corpus generator and ratio:\n",
        "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
        "\n",
        "    :param data: A corpus generator.\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the \n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "    \n",
        "    data = list(data)  \n",
        "    n = len(data)  \n",
        "    train_indices = random.sample(range(n), int(n * ratio))          \n",
        "    test_indices = list(set(range(n)) - set(train_indices))    \n",
        "    train = [data[i] for i in train_indices]           \n",
        "    test = [data[i] for i in test_indices]             \n",
        "    return (train, test)                       \n",
        " \n",
        "\n",
        "def get_train_test_data():\n",
        "    \n",
        "    #get ids of positive and negative movie reviews\n",
        "    pos_review_ids=movie_reviews.fileids('pos')\n",
        "    neg_review_ids=movie_reviews.fileids('neg')\n",
        "   \n",
        "    #split positive and negative data into training and testing sets\n",
        "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
        "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
        "    #add labels to the data and concatenate\n",
        "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
        "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
        "   \n",
        "    return training, testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3LWwBYICPP"
      },
      "source": [
        "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJLegkdPFUJA",
        "outputId": "04fd53ed-e03f-4707-8670-2248807136fc"
      },
      "source": [
        "#do not change the code in this cell\n",
        "random.seed(candidateno)\n",
        "training_data,testing_data=get_train_test_data()\n",
        "print(\"The amount of training data is {}\".format(len(training_data)))\n",
        "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
        "print(\"The representation of a single data item is below\")\n",
        "print(training_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of training data is 1400\n",
            "The amount of testing data is 600\n",
            "The representation of a single data item is below\n",
            "(['not', 'since', 'attending', 'an', 'ingmar', ...], 'pos')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHyiJlmzZaPB"
      },
      "source": [
        "**QUESTION 1**\n",
        "\n",
        "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
        "\n",
        "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
        "\n",
        "c) **Explain** what you have done and why\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0rwT7DOezka"
      },
      "source": [
        "**Snippet From our Training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtrieoTNemt5",
        "outputId": "89dde2f4-a612-4489-c668-bcd683e96bc1"
      },
      "source": [
        "print(list(training_data[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['not', 'since', 'attending', 'an', 'ingmar', 'bergman', 'retrospective', 'a', 'few', 'years', 'ago', 'have', 'i', 'seen', 'a', 'film', 'as', 'uncompromising', 'in', 'its', 'portrayal', 'of', 'emotional', 'truth', 'as', 'secrets', '&', 'lies', '.', 'like', 'bergman', ',', 'director', 'mike', 'leigh', 'is', 'interested', 'in', 'probing', 'his', 'characters', \"'\", 'inner', 'depths', 'through', 'hypernaturally', 'blunt', 'confrontations', '.', 'also', 'like', 'bergman', ',', 'leigh', 'engages', 'in', 'frequent', 'closeups', 'of', 'his', 'characters', \"'\", 'ravished', 'and', 'wracked', 'faces', '.', 'and', 'the', 'prominent', 'mournfulness', 'of', 'a', 'cello', 'on', 'the', 'soundtrack', 'recalls', 'bergman', \"'\", 's', 'own', 'use', 'of', 'a', 'bach', 'cello', 'suite', 'in', 'an', 'earlier', 'film', '.', 'all', 'that', 'is', 'missing', 'is', 'a', 'discussion', 'of', 'god', '.', 'which', 'is', 'not', 'to', 'say', 'that', 'secrets', '&', 'lies', 'is', 'nothing', 'more', 'than', 'an', 'homage', 'to', 'the', 'swedish', 'master', '.', 'in', 'fact', ',', 'it', 'is', 'quite', 'possible', 'leigh', 'had', 'no', 'such', 'intentions', 'in', 'mind', '.', 'nonetheless', ',', 'what', 'we', 'get', 'is', 'so', 'far', 'removed', 'from', 'the', 'average', 'moviegoing', 'experience', '--', 'even', 'from', 'the', 'reason', 'we', 'go', 'to', 'the', 'movies', 'in', 'the', 'first', 'place', '--', 'that', 'it', 'takes', 'some', 'effort', 'to', 'adjust', 'to', 'the', 'film', \"'\", 's', 'rhythms', '.', 'once', 'the', 'adjustment', 'is', 'made', ',', 'however', ',', 'there', 'are', 'great', 'rewards', '.', 'one', 'such', 'is', 'the', 'chance', 'to', 'see', 'life', 'on', 'the', 'screen', 'as', 'it', 'really', 'is', '.', 'though', 'leigh', 'may', 'have', 'adopted', 'some', 'of', 'bergman', \"'\", 's', 'stylistic', 'touches', ',', 'most', 'obviously', 'in', 'an', 'early', 'scene', 'of', 'terse', 'cross', '-', 'cutting', 'during', 'a', 'married', 'couple', \"'\", 's', 'strained', 'conversation', ',', 'as', 'well', 'as', 'in', 'that', 'somewhat', 'obtrusive', 'score', ',', 'the', 'overall', 'feeling', 'of', 'the', 'film', 'is', 'that', 'it', 'eschews', 'any', '\"', 'style', '\"', 'at', 'all', '.', 'whereas', 'bergman', 'uses', 'artifice', 'as', 'a', 'tool', 'to', 'expose', 'reality', ',', 'leigh', 'makes', 'the', 'camera', 'a', 'mere', 'observer', ',', 'almost', 'as', 'in', 'a', 'pbs', 'documentary', '.', 'the', 'effect', 'of', 'this', 'is', 'to', 'focus', 'all', 'of', 'your', 'attention', 'on', 'the', 'actors', '.', 'it', 'is', 'a', 'tribute', 'to', 'everyone', 'involved', 'that', ',', 'despite', 'such', 'scrutiny', ',', 'only', 'infrequently', 'are', 'we', 'aware', 'that', 'anyone', '*', 'is', '*', 'acting', '.', 'much', 'has', 'been', 'made', 'of', 'brenda', 'blethyn', \"'\", 's', 'performance', ',', 'and', 'rightly', 'so', ',', 'but', 'it', 'is', 'only', 'when', 'you', 'remind', 'yourself', 'that', 'you', 'are', 'watching', 'a', 'fiction', 'that', 'you', 'realize', 'how', 'good', 'she', 'is', '.', 'there', 'are', 'a', 'few', 'missteps', '.', 'for', 'one', ',', 'except', 'for', 'one', 'scene', '(', 'tragicomic', ',', 'as', 'it', 'happens', ')', ',', 'there', 'is', 'scant', 'humor', 'in', 'the', 'film', '.', 'this', 'leads', 'to', 'a', 'certain', 'monotonous', 'tone', 'throughout', '.', 'and', 'occasionally', '(', 'as', 'with', 'bergman', ')', 'the', 'bluntness', 'of', 'the', 'situations', 'can', 'seem', 'forced', '.', 'for', 'all', 'that', ',', 'this', 'longish', 'film', 'manages', 'to', 'keep', 'hold', 'of', 'your', 'attention', '.', 'it', 'is', 'unfortunate', 'that', 'the', 'audience', 'for', 'secrets', '&', 'lies', 'will', 'most', 'likely', 'be', 'limited', 'to', 'an', 'intellectual', 'elite', ',', 'for', 'there', 'is', 'nothing', 'inherently', 'intellectual', 'about', 'this', 'film', '.', 'in', 'fact', ',', 'it', 'might', 'easily', 'resonate', 'more', 'strongly', 'for', 'millions', 'of', 'working', 'class', 'filmgoers', 'who', 'will', 'likely', 'never', 'see', 'it', '.', 'there', 'is', 'even', 'a', 'sweet', 'but', 'significant', 'irony', 'in', 'the', 'film', \"'\", 's', 'unspoken', 'take', 'on', 'race', 'relations', ',', 'something', 'an', 'american', 'audience', 'at', 'least', 'would', 'do', 'well', 'to', 'observe', '.', 'nonetheless', ',', 'secrets', '&', 'lies', 'is', 'not', 'for', 'the', 'faint', 'of', 'heart', '.', 'though', 'there', 'is', 'nothing', 'physically', 'horrific', 'to', 'make', 'one', 'squeamish', ',', 'the', 'exploration', 'of', 'common', 'human', 'frailty', 'can', 'be', 'so', 'raw', 'and', 'unsparing', 'that', 'it', 'is', 'tempting', 'to', 'turn', 'from', 'the', 'screen', '.', 'needless', 'to', 'say', ',', 'it', 'is', 'also', 'very', 'depressing', 'at', 'times', '.', 'but', 'for', 'many', 'of', 'us', ',', 'of', 'course', ',', 'so', 'is', 'life', '.', 'and', 'though', 'the', 'film', 'is', 'too', 'honest', 'to', 'tack', 'on', 'a', 'phony', 'happy', 'ending', ',', 'that', 'same', 'honesty', 'allows', 'it', 'to', 'admit', 'that', 'things', 'can', 'also', 'get', 'better', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOdF2QOJply0"
      },
      "source": [
        "**Normalising data**\n",
        "\n",
        "Our data is split into 30% Test and 70% training, However, it not normalised yet. We could notice in the code cell above that there is still some stopwords and not alphabetic words in our **training** and **testing** data. Therefore we have to pre-process our data using the **`normalise`** function before working with it. Since the goal of our application is to classify **positive** and **negative** reviews, we won't need to dinstinguish between uppercase or lower case words and numbers( we do not need symbols as well) would be irrelevant in the classification of our document. Having done so, we would reduce redundancy and duplicates data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diWrz8OcdWgI"
      },
      "source": [
        "stop = stopwords.words('english') #getting stops from English dic\n",
        "# normalise the worlist\n",
        "def normalise(wordlist):\n",
        "    lowered=[word.lower() for word in wordlist if word.isalpha() and word not in stop]\n",
        "    return lowered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sduO_MehdbvB"
      },
      "source": [
        "training_norm=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in training_data] #store the normalized training data\n",
        "testing_norm=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in testing_data] # store the normalized testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIWDSexNtg3o"
      },
      "source": [
        "**BAG OF WORDS REPRESENTATION**\n",
        "\n",
        "Using raw text in NLP is impossible, therefore we have to extract features from our data/text. Since we are dealing with document classification, we can discard the order of the words and  only count the occurences of words since similar documents should have more or less same words. we used a library funciton called FreqDist from nltk.probability which will generate our bag of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLza7IPidpS7"
      },
      "source": [
        "pos_freq_dist= FreqDist()\n",
        "neg_freq_dist= FreqDist()\n",
        "def Bag_of_words(Training_data):  #Bag of words representation\n",
        "  global pos_freq_dist,neg_freq_dist #define var\n",
        "  for reviewDist,label in Training_data:\n",
        "     if label=='pos':\n",
        "        pos_freq_dist+=reviewDist #store positive reviews\n",
        "     else:\n",
        "        neg_freq_dist+=reviewDist #store negative reviews\n",
        "  return (pos_freq_dist, neg_freq_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-oIAjuEwO-I"
      },
      "source": [
        "Here, is the output of our positve and negative frequenecy distribution or the bag of words representation in the normalised training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioEFO9tb9cg4",
        "outputId": "a05277cf-fc27-4534-9209-72c1011282c3"
      },
      "source": [
        "pos_freq, neg_freq = Bag_of_words(training_norm) # convert the normalised data to a bag of words.\n",
        "pos_freq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'since': 266,\n",
              "          'attending': 6,\n",
              "          'ingmar': 3,\n",
              "          'bergman': 13,\n",
              "          'retrospective': 2,\n",
              "          'years': 336,\n",
              "          'ago': 67,\n",
              "          'seen': 389,\n",
              "          'film': 3667,\n",
              "          'uncompromising': 6,\n",
              "          'portrayal': 51,\n",
              "          'emotional': 116,\n",
              "          'truth': 72,\n",
              "          'secrets': 19,\n",
              "          'lies': 59,\n",
              "          'like': 1239,\n",
              "          'director': 407,\n",
              "          'mike': 56,\n",
              "          'leigh': 17,\n",
              "          'interested': 42,\n",
              "          'probing': 1,\n",
              "          'characters': 704,\n",
              "          'inner': 18,\n",
              "          'depths': 11,\n",
              "          'hypernaturally': 1,\n",
              "          'blunt': 5,\n",
              "          'confrontations': 4,\n",
              "          'also': 855,\n",
              "          'engages': 8,\n",
              "          'frequent': 13,\n",
              "          'closeups': 1,\n",
              "          'ravished': 1,\n",
              "          'wracked': 1,\n",
              "          'faces': 31,\n",
              "          'prominent': 14,\n",
              "          'mournfulness': 1,\n",
              "          'cello': 4,\n",
              "          'soundtrack': 60,\n",
              "          'recalls': 6,\n",
              "          'use': 159,\n",
              "          'bach': 3,\n",
              "          'suite': 9,\n",
              "          'earlier': 62,\n",
              "          'missing': 49,\n",
              "          'discussion': 13,\n",
              "          'god': 104,\n",
              "          'say': 293,\n",
              "          'nothing': 233,\n",
              "          'homage': 26,\n",
              "          'swedish': 1,\n",
              "          'master': 79,\n",
              "          'fact': 286,\n",
              "          'quite': 284,\n",
              "          'possible': 83,\n",
              "          'intentions': 18,\n",
              "          'mind': 162,\n",
              "          'nonetheless': 30,\n",
              "          'get': 631,\n",
              "          'far': 225,\n",
              "          'removed': 13,\n",
              "          'average': 56,\n",
              "          'moviegoing': 1,\n",
              "          'experience': 101,\n",
              "          'even': 845,\n",
              "          'reason': 112,\n",
              "          'go': 400,\n",
              "          'movies': 468,\n",
              "          'first': 691,\n",
              "          'place': 242,\n",
              "          'takes': 277,\n",
              "          'effort': 41,\n",
              "          'adjust': 1,\n",
              "          'rhythms': 4,\n",
              "          'adjustment': 1,\n",
              "          'made': 372,\n",
              "          'however': 401,\n",
              "          'great': 547,\n",
              "          'rewards': 3,\n",
              "          'one': 2128,\n",
              "          'chance': 82,\n",
              "          'see': 710,\n",
              "          'life': 754,\n",
              "          'screen': 274,\n",
              "          'really': 553,\n",
              "          'though': 352,\n",
              "          'may': 369,\n",
              "          'adopted': 8,\n",
              "          'stylistic': 10,\n",
              "          'touches': 30,\n",
              "          'obviously': 68,\n",
              "          'early': 102,\n",
              "          'scene': 509,\n",
              "          'terse': 1,\n",
              "          'cross': 41,\n",
              "          'cutting': 20,\n",
              "          'married': 68,\n",
              "          'couple': 135,\n",
              "          'strained': 5,\n",
              "          'conversation': 20,\n",
              "          'well': 801,\n",
              "          'somewhat': 70,\n",
              "          'obtrusive': 1,\n",
              "          'score': 99,\n",
              "          'overall': 83,\n",
              "          'feeling': 89,\n",
              "          'eschews': 5,\n",
              "          'style': 138,\n",
              "          'whereas': 12,\n",
              "          'uses': 90,\n",
              "          'artifice': 3,\n",
              "          'tool': 10,\n",
              "          'expose': 5,\n",
              "          'reality': 86,\n",
              "          'makes': 394,\n",
              "          'camera': 111,\n",
              "          'mere': 25,\n",
              "          'observer': 3,\n",
              "          'almost': 304,\n",
              "          'pbs': 2,\n",
              "          'documentary': 30,\n",
              "          'effect': 63,\n",
              "          'focus': 60,\n",
              "          'attention': 104,\n",
              "          'actors': 241,\n",
              "          'tribute': 15,\n",
              "          'everyone': 185,\n",
              "          'involved': 92,\n",
              "          'despite': 148,\n",
              "          'scrutiny': 3,\n",
              "          'infrequently': 2,\n",
              "          'aware': 26,\n",
              "          'anyone': 138,\n",
              "          'acting': 224,\n",
              "          'much': 740,\n",
              "          'brenda': 1,\n",
              "          'blethyn': 1,\n",
              "          'performance': 374,\n",
              "          'rightly': 3,\n",
              "          'remind': 11,\n",
              "          'watching': 171,\n",
              "          'fiction': 141,\n",
              "          'realize': 63,\n",
              "          'good': 910,\n",
              "          'missteps': 10,\n",
              "          'except': 57,\n",
              "          'tragicomic': 1,\n",
              "          'happens': 82,\n",
              "          'scant': 2,\n",
              "          'humor': 139,\n",
              "          'leads': 89,\n",
              "          'certain': 85,\n",
              "          'monotonous': 4,\n",
              "          'tone': 51,\n",
              "          'throughout': 135,\n",
              "          'occasionally': 50,\n",
              "          'bluntness': 2,\n",
              "          'situations': 58,\n",
              "          'seem': 216,\n",
              "          'forced': 79,\n",
              "          'longish': 1,\n",
              "          'manages': 94,\n",
              "          'keep': 136,\n",
              "          'hold': 47,\n",
              "          'unfortunate': 30,\n",
              "          'audience': 302,\n",
              "          'likely': 55,\n",
              "          'limited': 35,\n",
              "          'intellectual': 20,\n",
              "          'elite': 12,\n",
              "          'inherently': 6,\n",
              "          'might': 202,\n",
              "          'easily': 92,\n",
              "          'resonate': 2,\n",
              "          'strongly': 20,\n",
              "          'millions': 14,\n",
              "          'working': 72,\n",
              "          'class': 79,\n",
              "          'filmgoers': 1,\n",
              "          'never': 503,\n",
              "          'sweet': 80,\n",
              "          'significant': 23,\n",
              "          'irony': 18,\n",
              "          'unspoken': 7,\n",
              "          'take': 319,\n",
              "          'race': 45,\n",
              "          'relations': 2,\n",
              "          'something': 359,\n",
              "          'american': 241,\n",
              "          'least': 193,\n",
              "          'would': 723,\n",
              "          'observe': 5,\n",
              "          'faint': 3,\n",
              "          'heart': 137,\n",
              "          'physically': 13,\n",
              "          'horrific': 14,\n",
              "          'make': 578,\n",
              "          'squeamish': 4,\n",
              "          'exploration': 11,\n",
              "          'common': 52,\n",
              "          'human': 201,\n",
              "          'frailty': 1,\n",
              "          'raw': 18,\n",
              "          'unsparing': 2,\n",
              "          'tempting': 3,\n",
              "          'turn': 142,\n",
              "          'needless': 12,\n",
              "          'depressing': 13,\n",
              "          'times': 234,\n",
              "          'many': 532,\n",
              "          'us': 408,\n",
              "          'course': 193,\n",
              "          'honest': 44,\n",
              "          'tack': 1,\n",
              "          'phony': 8,\n",
              "          'happy': 88,\n",
              "          'ending': 189,\n",
              "          'honesty': 11,\n",
              "          'allows': 51,\n",
              "          'admit': 43,\n",
              "          'things': 333,\n",
              "          'better': 281,\n",
              "          'note': 86,\n",
              "          'consider': 46,\n",
              "          'portions': 11,\n",
              "          'following': 69,\n",
              "          'text': 13,\n",
              "          'spoilers': 25,\n",
              "          'forewarned': 12,\n",
              "          'startling': 14,\n",
              "          'distributors': 4,\n",
              "          'worriedly': 1,\n",
              "          'rearrange': 1,\n",
              "          'summer': 116,\n",
              "          'release': 96,\n",
              "          'schedules': 1,\n",
              "          'order': 111,\n",
              "          'give': 176,\n",
              "          'annual': 10,\n",
              "          'disney': 135,\n",
              "          'animated': 78,\n",
              "          'feature': 89,\n",
              "          'juggernaut': 2,\n",
              "          'wide': 34,\n",
              "          'berth': 1,\n",
              "          'lion': 9,\n",
              "          'king': 86,\n",
              "          'cracked': 7,\n",
              "          'million': 68,\n",
              "          'domestic': 10,\n",
              "          'gross': 15,\n",
              "          'become': 207,\n",
              "          'profitable': 7,\n",
              "          'ventures': 7,\n",
              "          'history': 111,\n",
              "          'continuing': 8,\n",
              "          'build': 40,\n",
              "          'sturdy': 4,\n",
              "          'base': 17,\n",
              "          'left': 162,\n",
              "          'prior': 23,\n",
              "          'flicks': 35,\n",
              "          'aladdin': 8,\n",
              "          'beauty': 72,\n",
              "          'beast': 18,\n",
              "          'features': 82,\n",
              "          'shown': 53,\n",
              "          'unbroken': 2,\n",
              "          'string': 15,\n",
              "          'diminishing': 3,\n",
              "          'returns': 41,\n",
              "          'pocahontas': 5,\n",
              "          'hunchback': 6,\n",
              "          'notre': 5,\n",
              "          'dame': 8,\n",
              "          'year': 368,\n",
              "          'hercules': 4,\n",
              "          'successively': 1,\n",
              "          'proving': 15,\n",
              "          'less': 187,\n",
              "          'potent': 8,\n",
              "          'seemingly': 50,\n",
              "          'impregnable': 2,\n",
              "          'stranglehold': 1,\n",
              "          'market': 24,\n",
              "          'share': 55,\n",
              "          'suddenly': 39,\n",
              "          'looking': 179,\n",
              "          'mighty': 16,\n",
              "          'vulnerable': 12,\n",
              "          'faced': 30,\n",
              "          'serious': 76,\n",
              "          'competition': 17,\n",
              "          'fox': 48,\n",
              "          'anastasia': 6,\n",
              "          'brought': 53,\n",
              "          'xmas': 1,\n",
              "          'home': 226,\n",
              "          'dusting': 2,\n",
              "          'sparked': 5,\n",
              "          'modern': 67,\n",
              "          'revival': 9,\n",
              "          'animation': 76,\n",
              "          'little': 575,\n",
              "          'mermaid': 27,\n",
              "          'typically': 15,\n",
              "          'case': 144,\n",
              "          'films': 634,\n",
              "          'unquestionably': 5,\n",
              "          'top': 147,\n",
              "          'notch': 31,\n",
              "          'magic': 31,\n",
              "          'wonderful': 125,\n",
              "          'innocence': 29,\n",
              "          'story': 904,\n",
              "          'rousingly': 1,\n",
              "          'superb': 49,\n",
              "          'music': 198,\n",
              "          'storyline': 39,\n",
              "          'fairly': 60,\n",
              "          'straightforward': 21,\n",
              "          'young': 289,\n",
              "          'teen': 45,\n",
              "          'falls': 72,\n",
              "          'handsome': 17,\n",
              "          'man': 539,\n",
              "          'father': 213,\n",
              "          'disapproves': 3,\n",
              "          'assigns': 3,\n",
              "          'hapless': 8,\n",
              "          'chaperone': 2,\n",
              "          'daughter': 85,\n",
              "          'disobeys': 2,\n",
              "          'goes': 202,\n",
              "          'desperate': 27,\n",
              "          'lengths': 12,\n",
              "          'win': 47,\n",
              "          'crab': 4,\n",
              "          'object': 15,\n",
              "          'desire': 38,\n",
              "          'prince': 28,\n",
              "          'affecting': 15,\n",
              "          'emotionally': 40,\n",
              "          'resonant': 1,\n",
              "          'richness': 3,\n",
              "          'charm': 45,\n",
              "          'sheer': 32,\n",
              "          'clarity': 8,\n",
              "          'simplicity': 11,\n",
              "          'emotions': 55,\n",
              "          'moment': 115,\n",
              "          'ariel': 11,\n",
              "          'lays': 9,\n",
              "          'eyes': 108,\n",
              "          'eric': 18,\n",
              "          'resolutely': 4,\n",
              "          'smitten': 5,\n",
              "          'pure': 43,\n",
              "          'endearing': 29,\n",
              "          'character': 718,\n",
              "          'help': 197,\n",
              "          'invest': 3,\n",
              "          'simple': 122,\n",
              "          'touching': 48,\n",
              "          'love': 477,\n",
              "          'coupled': 5,\n",
              "          'healthy': 7,\n",
              "          'dose': 11,\n",
              "          'smart': 79,\n",
              "          'humour': 29,\n",
              "          'remarkably': 15,\n",
              "          'captivating': 13,\n",
              "          'picture': 230,\n",
              "          'interesting': 220,\n",
              "          'curiously': 6,\n",
              "          'dates': 4,\n",
              "          'voices': 28,\n",
              "          'cast': 282,\n",
              "          'motley': 8,\n",
              "          'crew': 80,\n",
              "          'produced': 49,\n",
              "          'distracting': 23,\n",
              "          'concept': 50,\n",
              "          'using': 88,\n",
              "          'celebrity': 16,\n",
              "          'became': 47,\n",
              "          'vogue': 3,\n",
              "          'started': 29,\n",
              "          'degree': 17,\n",
              "          'irrevocably': 2,\n",
              "          'exacerbated': 1,\n",
              "          'robin': 60,\n",
              "          'williams': 90,\n",
              "          'heralded': 3,\n",
              "          'henceforth': 1,\n",
              "          'majority': 18,\n",
              "          'voiced': 23,\n",
              "          'celebrities': 9,\n",
              "          'understandable': 8,\n",
              "          'lacking': 17,\n",
              "          'name': 113,\n",
              "          'recognition': 12,\n",
              "          'drawing': 21,\n",
              "          'power': 102,\n",
              "          'balto': 2,\n",
              "          'kevin': 112,\n",
              "          'bacon': 39,\n",
              "          'bridget': 8,\n",
              "          'fonda': 21,\n",
              "          'showcasing': 1,\n",
              "          'meg': 19,\n",
              "          'ryan': 84,\n",
              "          'john': 319,\n",
              "          'cusack': 19,\n",
              "          'strategy': 4,\n",
              "          'hype': 17,\n",
              "          'products': 3,\n",
              "          'embraced': 4,\n",
              "          'policy': 7,\n",
              "          'need': 105,\n",
              "          'hear': 49,\n",
              "          'demi': 2,\n",
              "          'moore': 31,\n",
              "          'esmerelda': 2,\n",
              "          'entertainment': 87,\n",
              "          'value': 18,\n",
              "          'augmented': 1,\n",
              "          'hearing': 20,\n",
              "          'recognizable': 8,\n",
              "          'voice': 128,\n",
              "          'rather': 240,\n",
              "          'best': 576,\n",
              "          'suits': 19,\n",
              "          'role': 360,\n",
              "          'exactly': 116,\n",
              "          'edge': 53,\n",
              "          'seat': 29,\n",
              "          'eddie': 40,\n",
              "          'murphy': 60,\n",
              "          'upcoming': 9,\n",
              "          'mulan': 73,\n",
              "          'fortunately': 22,\n",
              "          'performers': 21,\n",
              "          'although': 347,\n",
              "          'perhaps': 180,\n",
              "          'obscure': 9,\n",
              "          'impeccably': 4,\n",
              "          'chief': 17,\n",
              "          'among': 77,\n",
              "          'jodi': 2,\n",
              "          'benson': 7,\n",
              "          'tony': 38,\n",
              "          'nominee': 5,\n",
              "          'stage': 39,\n",
              "          'work': 364,\n",
              "          'crazy': 38,\n",
              "          'heroine': 27,\n",
              "          'perfection': 23,\n",
              "          'wonderfully': 57,\n",
              "          'expressive': 4,\n",
              "          'speaking': 33,\n",
              "          'full': 140,\n",
              "          'youthful': 4,\n",
              "          'vigor': 3,\n",
              "          'gorgeous': 22,\n",
              "          'singing': 20,\n",
              "          'ms': 26,\n",
              "          'provides': 53,\n",
              "          'engaging': 36,\n",
              "          'anchor': 9,\n",
              "          'catching': 12,\n",
              "          'flubber': 4,\n",
              "          'similarly': 10,\n",
              "          'samuel': 10,\n",
              "          'e': 56,\n",
              "          'wright': 8,\n",
              "          'terrific': 62,\n",
              "          'showy': 6,\n",
              "          'sebastian': 3,\n",
              "          'weary': 13,\n",
              "          'guardian': 9,\n",
              "          'milks': 3,\n",
              "          'lovable': 17,\n",
              "          'comic': 160,\n",
              "          'moments': 167,\n",
              "          'worth': 124,\n",
              "          'rendering': 3,\n",
              "          'two': 730,\n",
              "          'big': 336,\n",
              "          'tunes': 16,\n",
              "          'sea': 25,\n",
              "          'kiss': 30,\n",
              "          'girl': 135,\n",
              "          'stuff': 73,\n",
              "          'legend': 27,\n",
              "          'pat': 24,\n",
              "          'carrol': 1,\n",
              "          'deliciously': 14,\n",
              "          'villainous': 6,\n",
              "          'vampy': 1,\n",
              "          'evil': 144,\n",
              "          'witch': 22,\n",
              "          'ursula': 2,\n",
              "          'kenneth': 25,\n",
              "          'mars': 22,\n",
              "          'booming': 4,\n",
              "          'conveys': 10,\n",
              "          'stern': 10,\n",
              "          'yet': 266,\n",
              "          'affectionate': 5,\n",
              "          'authority': 14,\n",
              "          'triton': 2,\n",
              "          'large': 65,\n",
              "          'roles': 109,\n",
              "          'small': 161,\n",
              "          'edie': 1,\n",
              "          'mcclurg': 1,\n",
              "          'dotting': 1,\n",
              "          'busybody': 2,\n",
              "          'carlotta': 1,\n",
              "          'ideal': 24,\n",
              "          'rene': 4,\n",
              "          'auberjonois': 1,\n",
              "          'fun': 247,\n",
              "          'exuberant': 5,\n",
              "          'french': 60,\n",
              "          'chef': 5,\n",
              "          'probably': 202,\n",
              "          'remembered': 21,\n",
              "          'remarkable': 36,\n",
              "          'collection': 21,\n",
              "          'songs': 46,\n",
              "          'composed': 16,\n",
              "          'songwriting': 2,\n",
              "          'team': 97,\n",
              "          'alan': 41,\n",
              "          'menken': 5,\n",
              "          'howard': 35,\n",
              "          'ashman': 4,\n",
              "          'lyrics': 7,\n",
              "          'created': 78,\n",
              "          'shop': 35,\n",
              "          'horrors': 12,\n",
              "          'compose': 1,\n",
              "          'mr': 121,\n",
              "          'untimely': 2,\n",
              "          'death': 160,\n",
              "          'unbearably': 3,\n",
              "          'catchy': 14,\n",
              "          'charming': 47,\n",
              "          'fully': 47,\n",
              "          'integrated': 2,\n",
              "          'virtual': 16,\n",
              "          'extension': 3,\n",
              "          'dialogue': 150,\n",
              "          'consequently': 9,\n",
              "          'within': 87,\n",
              "          'context': 10,\n",
              "          'equally': 47,\n",
              "          'sequence': 135,\n",
              "          'christopher': 24,\n",
              "          'daniel': 26,\n",
              "          'barnes': 7,\n",
              "          'tour': 19,\n",
              "          'kingdom': 9,\n",
              "          'horse': 37,\n",
              "          'drawn': 34,\n",
              "          'carriage': 3,\n",
              "          'becomes': 180,\n",
              "          'magical': 23,\n",
              "          'wondrous': 9,\n",
              "          'fine': 111,\n",
              "          'appears': 66,\n",
              "          'people': 531,\n",
              "          'prefer': 7,\n",
              "          'delightfully': 7,\n",
              "          'colourful': 5,\n",
              "          'production': 111,\n",
              "          'number': 86,\n",
              "          'calypso': 1,\n",
              "          'styled': 6,\n",
              "          'joyfully': 1,\n",
              "          'crooned': 1,\n",
              "          'academy': 45,\n",
              "          'award': 42,\n",
              "          'golden': 23,\n",
              "          'globe': 11,\n",
              "          'awards': 20,\n",
              "          'song': 52,\n",
              "          'indeed': 47,\n",
              "          'joys': 6,\n",
              "          'screening': 16,\n",
              "          'listening': 17,\n",
              "          'children': 143,\n",
              "          'scattered': 6,\n",
              "          'along': 183,\n",
              "          'tune': 15,\n",
              "          'favourite': 5,\n",
              "          'heartfelt': 11,\n",
              "          'rendition': 10,\n",
              "          'ballad': 4,\n",
              "          'part': 277,\n",
              "          'world': 470,\n",
              "          'achingly': 2,\n",
              "          'beautiful': 147,\n",
              "          'yearning': 6,\n",
              "          'hope': 96,\n",
              "          'lyricized': 1,\n",
              "          'accompanied': 7,\n",
              "          'dazzlingly': 3,\n",
              "          'polished': 6,\n",
              "          'packs': 6,\n",
              "          'wallop': 2,\n",
              "          'literally': 34,\n",
              "          'tears': 22,\n",
              "          'reprise': 3,\n",
              "          'builds': 15,\n",
              "          'crescendo': 2,\n",
              "          'arching': 1,\n",
              "          'rock': 64,\n",
              "          'wave': 16,\n",
              "          'crashes': 9,\n",
              "          'cumulative': 2,\n",
              "          'short': 122,\n",
              "          'breathtaking': 26,\n",
              "          'acutely': 3,\n",
              "          'single': 74,\n",
              "          'instance': 23,\n",
              "          'finest': 33,\n",
              "          'writing': 62,\n",
              "          'november': 6,\n",
              "          'come': 294,\n",
              "          'end': 394,\n",
              "          'day': 275,\n",
              "          'question': 89,\n",
              "          'primary': 27,\n",
              "          'motivation': 5,\n",
              "          'reissue': 5,\n",
              "          'timing': 20,\n",
              "          'reinforce': 1,\n",
              "          'dominance': 2,\n",
              "          'provide': 52,\n",
              "          'direct': 34,\n",
              "          'costly': 4,\n",
              "          'new': 502,\n",
              "          'upstart': 2,\n",
              "          'division': 4,\n",
              "          'major': 112,\n",
              "          'venture': 14,\n",
              "          'every': 320,\n",
              "          'respect': 25,\n",
              "          'success': 98,\n",
              "          'grosses': 1,\n",
              "          'pushed': 8,\n",
              "          'mark': 74,\n",
              "          'proved': 11,\n",
              "          'strong': 117,\n",
              "          'initially': 31,\n",
              "          'released': 89,\n",
              "          'eight': 42,\n",
              "          'homes': 8,\n",
              "          'video': 96,\n",
              "          'pulling': 14,\n",
              "          'close': 103,\n",
              "          'opening': 112,\n",
              "          'weekend': 24,\n",
              "          'nobody': 26,\n",
              "          'could': 459,\n",
              "          'possibly': 45,\n",
              "          'expect': 78,\n",
              "          'defeat': 12,\n",
              "          'aggressively': 3,\n",
              "          'marketed': 4,\n",
              "          'head': 149,\n",
              "          'siphoned': 1,\n",
              "          'enough': 298,\n",
              "          'totals': 2,\n",
              "          'coveted': 2,\n",
              "          'leader': 45,\n",
              "          'spot': 26,\n",
              "          'allowing': 24,\n",
              "          'odious': 3,\n",
              "          'sweep': 10,\n",
              "          'subsequent': 13,\n",
              "          'week': 41,\n",
              "          'wrestle': 1,\n",
              "          'family': 308,\n",
              "          'demographic': 2,\n",
              "          'away': 238,\n",
              "          'motives': 16,\n",
              "          'self': 119,\n",
              "          'serving': 16,\n",
              "          'protectionist': 1,\n",
              "          'real': 368,\n",
              "          'winner': 25,\n",
              "          'public': 34,\n",
              "          'put': 157,\n",
              "          'back': 395,\n",
              "          'theatres': 6,\n",
              "          'true': 204,\n",
              "          'joy': 36,\n",
              "          'heartwarming': 6,\n",
              "          'gem': 19,\n",
              "          'silver': 23,\n",
              "          'renaissance': 3,\n",
              "          'greatest': 65,\n",
              "          'ever': 295,\n",
              "          'extraordinary': 26,\n",
              "          'australian': 14,\n",
              "          'shine': 17,\n",
              "          'scooped': 2,\n",
              "          'pool': 12,\n",
              "          'institute': 3,\n",
              "          'picking': 13,\n",
              "          'actor': 206,\n",
              "          'etc': 37,\n",
              "          'add': 53,\n",
              "          'gritty': 19,\n",
              "          'anguish': 7,\n",
              "          'courage': 19,\n",
              "          'friendship': 30,\n",
              "          'group': 130,\n",
              "          'male': 40,\n",
              "          'prisoners': 17,\n",
              "          'hiv': 2,\n",
              "          'positive': 20,\n",
              "          'section': 13,\n",
              "          'jail': 24,\n",
              "          'catastrophes': 3,\n",
              "          'low': 59,\n",
              "          'budget': 49,\n",
              "          'straight': 61,\n",
              "          'gay': 50,\n",
              "          'near': 81,\n",
              "          'university': 10,\n",
              "          'campus': 6,\n",
              "          'recall': 20,\n",
              "          'rich': 99,\n",
              "          'varied': 4,\n",
              "          'celluloid': 6,\n",
              "          'library': 6,\n",
              "          'unleashed': 1,\n",
              "          'australia': 11,\n",
              "          'bookend': 4,\n",
              "          'stand': 50,\n",
              "          'dead': 134,\n",
              "          'credits': 64,\n",
              "          'theme': 51,\n",
              "          'established': 14,\n",
              "          'clear': 79,\n",
              "          'distinct': 8,\n",
              "          'lines': 93,\n",
              "          'separating': 2,\n",
              "          'last': 312,\n",
              "          'names': 23,\n",
              "          'bryan': 3,\n",
              "          'brown': 51,\n",
              "          'desert': 20,\n",
              "          'settlement': 4,\n",
              "          'hundreds': 18,\n",
              "          'kilometres': 1,\n",
              "          'nearest': 2,\n",
              "          'town': 162,\n",
              "          'uneasy': 6,\n",
              "          'calm': 18,\n",
              "          'local': 80,\n",
              "          'aboriginals': 2,\n",
              "          'handful': 23,\n",
              "          'white': 117,\n",
              "          'settlers': 3,\n",
              "          'live': 154,\n",
              "          'nearby': 14,\n",
              "          'police': 71,\n",
              "          'officer': 39,\n",
              "          'task': 42,\n",
              "          'enforcing': 1,\n",
              "          'justice': 31,\n",
              "          'proud': 12,\n",
              "          'heritage': 7,\n",
              "          'behind': 159,\n",
              "          'naturally': 25,\n",
              "          'includes': 35,\n",
              "          'system': 50,\n",
              "          'key': 65,\n",
              "          'payback': 10,\n",
              "          'eye': 62,\n",
              "          'revenge': 32,\n",
              "          'usually': 79,\n",
              "          'extracted': 2,\n",
              "          'spearing': 1,\n",
              "          'recipient': 4,\n",
              "          'thigh': 2,\n",
              "          'balance': 19,\n",
              "          'admits': 10,\n",
              "          'bend': 3,\n",
              "          'rules': 36,\n",
              "          'bit': 234,\n",
              "          'including': 140,\n",
              "          'actively': 5,\n",
              "          'encouraging': 2,\n",
              "          'brutal': 19,\n",
              "          'warned': 7,\n",
              "          'start': 104,\n",
              "          'priest': 16,\n",
              "          'aboriginal': 3,\n",
              "          'fellas': 2,\n",
              "          'church': 22,\n",
              "          'foot': 18,\n",
              "          'either': 124,\n",
              "          'side': 133,\n",
              "          'line': 143,\n",
              "          'figuratively': 3,\n",
              "          'camps': 10,\n",
              "          'ernie': 6,\n",
              "          'dingo': 1,\n",
              "          'brings': 89,\n",
              "          'deal': 94,\n",
              "          'understanding': 30,\n",
              "          'middle': 68,\n",
              "          'churchman': 1,\n",
              "          'politician': 9,\n",
              "          'tension': 55,\n",
              "          'heat': 14,\n",
              "          'flies': 9,\n",
              "          'dust': 9,\n",
              "          'always': 247,\n",
              "          'whilst': 5,\n",
              "          'husband': 112,\n",
              "          'teacher': 47,\n",
              "          'lady': 30,\n",
              "          'kate': 38,\n",
              "          'milliken': 1,\n",
              "          'aborginal': 1,\n",
              "          'friend': 166,\n",
              "          'pedersen': 1,\n",
              "          'gone': 62,\n",
              "          'hills': 9,\n",
              "          'sacred': 6,\n",
              "          'site': 11,\n",
              "          'today': 67,\n",
              "          'strictly': 6,\n",
              "          'men': 216,\n",
              "          'know': 417,\n",
              "          'tells': 103,\n",
              "          'special': 201,\n",
              "          'initiation': 1,\n",
              "          'surrounded': 18,\n",
              "          'ancient': 20,\n",
              "          'art': 69,\n",
              "          'community': 28,\n",
              "          'finds': 142,\n",
              "          'sacrilegious': 3,\n",
              "          'act': 99,\n",
              "          'time': 862,\n",
              "          'fuse': 3,\n",
              "          'lit': 8,\n",
              "          'brittle': 2,\n",
              "          'inter': 2,\n",
              "          'racial': 7,\n",
              "          'peace': 15,\n",
              "          'shattered': 9,\n",
              "          'affected': 8,\n",
              "          'fall': 90,\n",
              "          'details': 60,\n",
              "          'finely': 10,\n",
              "          'crafted': 28,\n",
              "          'suffice': 13,\n",
              "          'rewarding': 10,\n",
              "          'co': 102,\n",
              "          'producing': 9,\n",
              "          'pivotal': 19,\n",
              "          'therefore': 45,\n",
              "          'flawed': 27,\n",
              "          'comments': 19,\n",
              "          'expects': 8,\n",
              "          'audiences': 75,\n",
              "          'feel': 227,\n",
              "          'warmth': 11,\n",
              "          'towards': 70,\n",
              "          'angry': 26,\n",
              "          'long': 281,\n",
              "          'visited': 2,\n",
              "          'central': 45,\n",
              "          'ayers': 1,\n",
              "          'uluru': 1,\n",
              "          'alice': 23,\n",
              "          'springs': 2,\n",
              "          'cinematography': 62,\n",
              "          'shows': 176,\n",
              "          'way': 646,\n",
              "          'captures': 23,\n",
              "          'vicious': 17,\n",
              "          'deteriorates': 1,\n",
              "          'moving': 82,\n",
              "          'slide': 4,\n",
              "          'show': 304,\n",
              "          'background': 58,\n",
              "          'dominates': 1,\n",
              "          'pesky': 1,\n",
              "          'foreground': 1,\n",
              "          'cultural': 17,\n",
              "          'clash': 11,\n",
              "          'provided': 26,\n",
              "          'thesis': 5,\n",
              "          'western': 25,\n",
              "          'birdcage': 4,\n",
              "          'three': 238,\n",
              "          'excellent': 113,\n",
              "          'covered': 22,\n",
              "          'anglo': 1,\n",
              "          'saxon': 3,\n",
              "          'invaders': 6,\n",
              "          'jedda': 1,\n",
              "          'chant': 2,\n",
              "          'jimmie': 2,\n",
              "          'blacksmith': 1,\n",
              "          'debate': 22,\n",
              "          'reared': 1,\n",
              "          'nourishing': 1,\n",
              "          'intelligent': 87,\n",
              "          'non': 74,\n",
              "          'judgemental': 1,\n",
              "          'sums': 6,\n",
              "          'asked': 30,\n",
              "          'black': 154,\n",
              "          'fella': 3,\n",
              "          'theater': 91,\n",
              "          'seeing': 135,\n",
              "          'david': 154,\n",
              "          'lynch': 22,\n",
              "          'lost': 129,\n",
              "          'highway': 12,\n",
              "          'remarked': 2,\n",
              "          'fellow': 44,\n",
              "          'movie': 1857,\n",
              "          'goer': 3,\n",
              "          'someone': 123,\n",
              "          'sucked': 11,\n",
              "          'brains': 11,\n",
              "          'nose': 10,\n",
              "          'ears': 9,\n",
              "          'five': 86,\n",
              "          'delivers': 55,\n",
              "          'second': 153,\n",
              "          'debut': 43,\n",
              "          'eraserhead': 2,\n",
              "          'weirdness': 5,\n",
              "          'scale': 31,\n",
              "          'happened': 56,\n",
              "          'certainly': 137,\n",
              "          'clues': 16,\n",
              "          'reasonable': 8,\n",
              "          'guesses': 2,\n",
              "          'difficult': 88,\n",
              "          'describe': 26,\n",
              "          'plot': 415,\n",
              "          'depends': 6,\n",
              "          'partly': 15,\n",
              "          'interpret': 3,\n",
              "          'l': 51,\n",
              "          'jazz': 10,\n",
              "          'saxophonist': 1,\n",
              "          'fred': 23,\n",
              "          'madison': 6,\n",
              "          'bill': 79,\n",
              "          'pullman': 8,\n",
              "          'wife': 230,\n",
              "          'renee': 4,\n",
              "          'patricia': 10,\n",
              "          'arquette': 15,\n",
              "          'clearly': 58,\n",
              "          'suspects': 22,\n",
              "          'infidelity': 6,\n",
              "          'receive': 13,\n",
              "          'series': 189,\n",
              "          'videotapes': 2,\n",
              "          'apparently': 47,\n",
              "          'filmed': 43,\n",
              "          'inside': 72,\n",
              "          'house': 136,\n",
              "          'asleep': 8,\n",
              "          'frightened': 10,\n",
              "          'confused': 33,\n",
              "          'matters': 27,\n",
              "          'mystery': 72,\n",
              "          'robert': 101,\n",
              "          'blake': 19,\n",
              "          'approaches': 16,\n",
              "          'party': 63,\n",
              "          'proceeds': 10,\n",
              "          'call': 75,\n",
              "          'telephone': 5,\n",
              "          'madisons': 1,\n",
              "          'hilarious': 96,\n",
              "          'unnerving': 6,\n",
              "          'next': 153,\n",
              "          'morning': 21,\n",
              "          'another': 387,\n",
              "          'videotape': 14,\n",
              "          'surprise': 92,\n",
              "          'brutally': 14,\n",
              "          ...})"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ2KwXWiwZUw"
      },
      "source": [
        "**GENERATING TOP 10 WORDS**\n",
        "\n",
        "After we normalised and we extracted the features from our training data using the bag words representation we define our `top_10`  function which takes our negative frequency distribution and positive distribution  and outputs k words in our case 10. \n",
        "\n",
        "The funciton takes  **three arguments**  two frequency distributions and a number which denotes the number of words to be taken from the pool of candidates of the most ferquent  words.  In other words, it order the words on how much they occur more in one of the frequencies distribution and then return the hightest scoring words in our case it is 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cufn0RyIZaPC"
      },
      "source": [
        "def top_10(pos, neg, topk): #find most frequent words \n",
        "  diff= pos-neg\n",
        "  sorted_diff= diff.most_common()\n",
        "  words=[word for (word,freq) in sorted_diff[:topk]]\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv0QUQglyKiq"
      },
      "source": [
        "`TopPos` stores our top 10 words denoting **positive reviews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9uE-2XaZaPD",
        "outputId": "731276c5-b1fe-4e81-e36f-de02dd44909f"
      },
      "source": [
        "TopPos=top_10(pos_freq, neg_freq, 10)\n",
        "TopPos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['film',\n",
              " 'life',\n",
              " 'also',\n",
              " 'great',\n",
              " 'well',\n",
              " 'story',\n",
              " 'best',\n",
              " 'world',\n",
              " 'many',\n",
              " 'films']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdVdQNyHyVbw"
      },
      "source": [
        "`TopNeg` stores our top 10 words denoting **negative reviews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZSvU0ysZaPD",
        "outputId": "dc426935-0d60-47ba-f359-532d83ec7d9e"
      },
      "source": [
        "TopNeg=top_10(neg_freq,pos_freq,  10)\n",
        "TopNeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bad',\n",
              " 'movie',\n",
              " 'plot',\n",
              " 'worst',\n",
              " 'even',\n",
              " 'boring',\n",
              " 'script',\n",
              " 'get',\n",
              " 'stupid',\n",
              " 'big']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApOQE6vND20"
      },
      "source": [
        "**2)QUESTION 2**\n",
        "\n",
        "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
        "\n",
        "b) **Explain** what you have done.\n",
        "\n",
        "[12.5\\%]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGZykX4jZaPE"
      },
      "source": [
        "**WORD CLASSIFIER**\n",
        "\n",
        "Since we have created our `TopPos` and `TopNeg` word lists we can define our word list classifier to classify our documents. \n",
        "\n",
        "In the cell below we define our word list classifier. Our word classifier class has three functions. In **`_init_`** we initialize the negative and positive word lists. Our **`classify`** function which takes words of a document and returns to which class the given document belongs to. It decrements the score by the word value whenever there is an occurence of a negative word and incerement by the word value if an occurence of a positive word is seen. If the score is negative the document is a negative review, and if it the score is positive then the document is in the positive class\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BThDMrcmODJy"
      },
      "source": [
        "from nltk.classify.api import ClassifierI\n",
        "import random\n",
        "\n",
        "class Word_Classifier(ClassifierI):\n",
        "  def __init__(self, pos, neg): \n",
        "        self._pos = pos \n",
        "        self._neg = neg \n",
        "\n",
        "  def classify(self, doc): \n",
        "        score = 0\n",
        "        \n",
        "        for word,value in doc.items():\n",
        "          if word in self._pos:\n",
        "            score+=value\n",
        "          if word in self._neg:\n",
        "            score -=value\n",
        "        # add code here that assigns an appropriate value to score\n",
        "        return \"neg\" if score < 0 else \"pos\"\n",
        "\n",
        "    ##we don't actually need to define the classify_many method as it is provided in ClassifierI\n",
        "    #def classify_many(self, docs): \n",
        "    #    return [self.classify(doc) for doc in docs] \n",
        "\n",
        "  def labels(self): \n",
        "        return (\"pos\", \"neg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HGN8rUXq46q"
      },
      "source": [
        "In the cell below, we pass the `TopPos` and `TopNeg` word lists to train our classifier and once done we pass the sentence as a bag of words to the classify method, to classify its class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nkIyTK6yfayF",
        "outputId": "f63ee942-e47a-4785-f8df-ced4a398f61a"
      },
      "source": [
        "Classifier_=Word_Classifier(TopPos,TopNeg) #Train our classifier\n",
        "Classifier_.classify(FreqDist(\"This movie was great\".split())) #Classify the sentence just for testing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pos'"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yipnVcJDsPL1"
      },
      "source": [
        "We used the `zip(*testing_norm)` function to split our normalised test data into pairs of lists, `docs` and `labels`. where `docs` is the bag of word representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTdw2MbiVKpb"
      },
      "source": [
        "docs,labels=zip(*testing_norm) #  split our testing data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEWJOvMLtAtE"
      },
      "source": [
        "In the cell below, we pass docs which is the bag of words representation of the testing data to our classifier to determine the documents classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-0SHeJ_Wpe-",
        "outputId": "e5df017c-8fa3-493d-918f-d89384bef7be"
      },
      "source": [
        "word_list_classifier_result=Classifier_.classify_many(docs) # Classify our Test Data\n",
        "word_list_classifier_result #Print the prediction reults"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9EbvaHNZaPG"
      },
      "source": [
        "**3)QUESTION 3**\n",
        "\n",
        "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
        "\n",
        "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrmlzDmghS7D"
      },
      "source": [
        "**Confusion Matrix**\n",
        "\n",
        "The confusion matrix below calculates the True positive, True negatice, False positive and False negative of the predictions of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-0jT3mNZaPG"
      },
      "source": [
        "class ConfusionMatrix:\n",
        "    def __init__(self,predictions,goldstandard,classes=(\"pos\",\"neg\")):\n",
        "    \n",
        "        (self.c1,self.c2)=classes\n",
        "        self.TP=0\n",
        "        self.FP=0\n",
        "        self.FN=0\n",
        "        self.TN=0\n",
        "        for p,g in zip(predictions,goldstandard):\n",
        "            if g==self.c1:\n",
        "                if p==self.c1:\n",
        "                    self.TP+=1\n",
        "                else:\n",
        "                    self.FN+=1\n",
        "        \n",
        "            elif p==self.c1:\n",
        "                self.FP+=1\n",
        "            else:\n",
        "                self.TN+=1\n",
        "        \n",
        "    \n",
        "    def accuracy(self):\n",
        "      a=0\n",
        "\n",
        "      a = (self.TP+self.TN)/(self.TP+self.TN+self.FP+self.FN)\n",
        "      return a\n",
        "\n",
        "    def precision(self):\n",
        "        p=0\n",
        "        #put your code to compute precision here\n",
        "        p = self.TP / (self.TP + self.FP)\n",
        "    \n",
        "        return p\n",
        "    \n",
        "  \n",
        "    def recall(self):\n",
        "        r=0\n",
        "        #put your code to compute recall here\n",
        "        r= self.TP/(self.TP + self.FN)\n",
        "        return r\n",
        "  \n",
        "    def f1(self):\n",
        "        f1=0\n",
        "        #put your code to compute f1 here\n",
        "        f1= 2 * (self.recall()*self.precision()/(self.recall()+self.precision()))\n",
        "        return f1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epN_67tNZaPG"
      },
      "source": [
        "score=ConfusionMatrix(Classifier_.classify_many(docs),labels) #calculate the score for the different evaluation method when classifying our testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX5GUduWhvpq"
      },
      "source": [
        "The code below displayes the score of each of the evaluation method using the prediction over our test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS-0D8Vo9Xtj",
        "outputId": "7e3d93f2-7c88-4a29-bc5d-3b70fd8f04d5"
      },
      "source": [
        "from tabulate import tabulate\n",
        "print(tabulate([['accuracy', score.accuracy()], ['precision', score.precision()],['recall', score.recall()], ['F1_score', score.f1()]],headers=['Name', 'score'])) #print the score of the different evaluation methods into a table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name          score\n",
            "---------  --------\n",
            "accuracy   0.656667\n",
            "precision  0.611905\n",
            "recall     0.856667\n",
            "F1_score   0.713889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2YkyShFZaPF"
      },
      "source": [
        "**ACCURACY**\n",
        "\n",
        "Accuracy basically the proportion of documents that were classified correctly over the total number of predictions.\n",
        "\n",
        "Evaluating the classifier ONLY in terms of accuracy is not a reasonable thing to do for several reasons (However, Accuracy might comes in handy for our project needs and goals, but in general it is a misleading type of evaluation). Also, in our case the classes are balanced, so accuracy is useful in our case.\n",
        "\n",
        "\n",
        "\n",
        "*   Accuracy can be misleading when the classes are unbalanced.For instance, if we have to classify our documents to two classes A and B, and we have 20% of documents in our Class A and 80% in our class B. The classifier that will classify all the documents as being class B will score 80%, which is a good score, but not reliable our classifier will keep oscillating between Big different accuracies ( For example, 20% accuracy if it classifies everything as A and will oscillate quickly if it classifies everything as class B).\n",
        "In other words, we can lower the cost and have greater accuracy just by predicting that every doc/data belongs to the majority class, and **clearly** that is not reliable and certain predictions can bypass the accuracy metric and mislead us.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS9UpmJNEAp"
      },
      "source": [
        "**4) QUESTION 4**\n",
        "\n",
        "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
        "\n",
        "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results. \n",
        "\n",
        "[12.5\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfK0a9Me2mkU"
      },
      "source": [
        "**NAIVE BAYES CLASSIFIER**\n",
        "\n",
        "We will use the standard Naive Bayes classifier imported from nltk.classify.\n",
        "\n",
        "Once imported we can train our model using the train method and pass to it the bag words representation of our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfd9dtbCZaPH"
      },
      "source": [
        "from nltk.classify import NaiveBayesClassifier #import the naive bayes classifier\n",
        "\n",
        "nltk_nb=NaiveBayesClassifier.train(training_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVIGwRkX5bMi"
      },
      "source": [
        "In the cell below, we pass the testing data to classify using our naive bayes classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM7umnLaZaPI",
        "outputId": "46ae8d39-6bee-4b9c-c6c2-d301295dd7dc"
      },
      "source": [
        "Naive_bayes_results=nltk_nb.classify_many(docs) #store the classification results in the variable\n",
        "Naive_bayes_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acNxFblgiTDn"
      },
      "source": [
        "In the cell below, we calculate the difference evaluation scores for our naive bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIzyFf0Yb2cn",
        "outputId": "6bdec9e1-1eb7-4b2d-a634-fdf06ae4d2bb"
      },
      "source": [
        "NB_score=ConfusionMatrix(nltk_nb.classify_many(docs),labels)\n",
        "print(tabulate([['accuracy', NB_score.accuracy()], ['precision', NB_score.precision()],['recall', NB_score.recall()], ['F1_score', NB_score.f1()]],headers=['Name', 'score']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name          score\n",
            "---------  --------\n",
            "accuracy   0.725\n",
            "precision  0.651007\n",
            "recall     0.97\n",
            "F1_score   0.779116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DRAt0gWC58v"
      },
      "source": [
        "**Comparison**\n",
        "\n",
        "The above evaluation for the Naive bayes algorithm is when we train our classifier on 700 by 700 data of negative and positive reviews respectiveley.\n",
        "\n",
        "The evaluation we had for the word classifier was only 10 by 10 words list to train our classifier.\n",
        "\n",
        "To have a more robust comparision between the wordlist and the Naive Bayes classifier we should compare it while using the same amount of training data. In the cell below I will compare both classifiers using 1, 20, 100, 400, 700 training data split to feed to our classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmloZDauA46R"
      },
      "source": [
        "from random import sample\n",
        "sample_sizes=[1,20,100,400,700] # Define different sample sizes\n",
        "\n",
        "total_dict_result={} # store the data in a dictionary for both Naive based classifier and Word list classifier\n",
        "for size in sample_sizes:\n",
        "  WC_res={} # store the accuracy result for Word list\n",
        "  NB_res={} #sote the accuracy result for the Naive bayes result\n",
        "\n",
        "  positive_training=[(doc,label) for (doc,label) in training_norm if label==\"pos\"] # Store normalised positive data\n",
        "  negative_training=[(doc,label) for (doc,label) in training_norm if label==\"neg\"] # Store normalised negative data\n",
        "\n",
        "  Positive_data=top_10(pos_freq, neg_freq, size) # generate the positive data with a certain size\n",
        "  Negative_data= top_10(neg_freq,pos_freq, size) # generate the negative data with a certain size\n",
        "\n",
        "  training_sample=sample(positive_training,size)+sample(negative_training,size) # randomizing the data choosing\n",
        "\n",
        "  Naive_Bayes_Classifier=NaiveBayesClassifier.train(training_sample) #Training the Naive Bayes \n",
        "\n",
        "  W_Classifier=Word_Classifier(Positive_data,Negative_data) # Training the Word List classifier\n",
        "\n",
        "  Word_Classifier_score=ConfusionMatrix(W_Classifier.classify_many(docs),labels).accuracy() # calculate the accuracy for the word list classifier\n",
        "\n",
        "  Naive_Bayes_score= ConfusionMatrix(Naive_Bayes_Classifier.classify_many(docs),labels).accuracy() # calculate the accuracy for the Naive Bayes classifier\n",
        "  \n",
        "  #storing accuracy scores\n",
        "  WC_res[\"Word Classifiers\"]=Word_Classifier_score \n",
        "  NB_res[\"Naive Bayes classifier\"] =Naive_Bayes_score\n",
        "  \n",
        "  #storing both accuracy scores in a nesteed dictionary\n",
        "  total_dict_result[size]=WC_res\n",
        "  total_dict_result[size].update(NB_res)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0riOJvNULDku",
        "outputId": "b2c87232-013a-405a-c525-5b71c8d0f79c"
      },
      "source": [
        "total_dict_result # Displaying our nested dictionary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'Naive Bayes classifier': 0.5283333333333333,\n",
              "  'Word Classifiers': 0.5416666666666666},\n",
              " 20: {'Naive Bayes classifier': 0.5766666666666667, 'Word Classifiers': 0.68},\n",
              " 100: {'Naive Bayes classifier': 0.745,\n",
              "  'Word Classifiers': 0.6416666666666667},\n",
              " 400: {'Naive Bayes classifier': 0.7116666666666667,\n",
              "  'Word Classifiers': 0.665},\n",
              " 700: {'Naive Bayes classifier': 0.725,\n",
              "  'Word Classifiers': 0.6616666666666666}}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LJymYreeRKIA",
        "outputId": "d7d507a3-8ebd-4cfc-ea5c-26accbbb113b"
      },
      "source": [
        "df1=pd.DataFrame(total_dict_result)\n",
        "df1=df1.transpose()\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word Classifiers</th>\n",
              "      <th>Naive Bayes classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.528333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.576667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.641667</td>\n",
              "      <td>0.745000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>0.665000</td>\n",
              "      <td>0.711667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>0.661667</td>\n",
              "      <td>0.725000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Word Classifiers  Naive Bayes classifier\n",
              "1            0.541667                0.528333\n",
              "20           0.680000                0.576667\n",
              "100          0.641667                0.745000\n",
              "400          0.665000                0.711667\n",
              "700          0.661667                0.725000"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "5yFA4r6QRc8j",
        "outputId": "802d6513-a5e9-4a01-c8aa-d604fa69dd68"
      },
      "source": [
        "ax = df1.plot(kind=\"line\",title=\"Accuracy(Naive Bayes and Word Classifier) Vs Sample Size\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_xlabel(\"Sample Size\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Sample Size')"
            ]
          },
          "metadata": {},
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydg6wZL3US1f"
      },
      "source": [
        "**Discussion**\n",
        "\n",
        "We have run both of our classifier over multiple sizes of data, and from the experiment we could see that in general Naive Bayes classifier is better than the word list classifier.\n",
        "\n",
        "When the data fed to our classifier the word classifier proformed slightly better than the Naive bayes, but once we added more and more training, Naive bayes jumped by a big margin and kept rising while the Word classifier started decreasing at the end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGDXaVDqOSfY"
      },
      "source": [
        "**5) QUESTION 5**\n",
        "\n",
        "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions. \n",
        "\n",
        "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
        "\n",
        "[25\\%]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y7IH5UZWqx5"
      },
      "source": [
        "**IMPACT OF LENGTH OF WORDLISTS ON THE WORD LIST CLASSIFIER**\n",
        "\n",
        "Basically, we will explore the impact of the quantity of our training data on the performance of our Word List classifier.\n",
        "\n",
        "In the code below, we have used samples of 1, 10, 50 to 700 data sizes.  \n",
        "\n",
        "*   We have 700 positive training reviews and 700 negative which makes our training balanced, which is why we should stop at the maximum of 700, othewise it will be unbalanced. In other words, we selected samples that have equal positive and negative reviews.\n",
        "*   We have used the random sample to generate random reviews and we have averaged them over the number of runs which we chose to be 3. we could have chose whaterver number of runs, the more the accurate, but we would stick with 3 just for the sake of demonstration.\n",
        "\n",
        "\n",
        "*   the function top_10 generates for us the negative and positive reviews of different sizes which we use to train our classifier on, and we calculate the accuracy accordinly. we have used the accuracy as a metric, since there wouldnt be much of a drawback or misleading as our training data is balanced.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asIJoU-zZaPI"
      },
      "source": [
        "from random import sample\n",
        "\n",
        "sample_sizes=[1,10,50,100,200,400,600, 700] # data sizes samples\n",
        "Names = {\"Word Classifiers\"} \n",
        "results={} # Dict for storing our accuracy results\n",
        "number_of_runs=3\n",
        "\n",
        "for size in sample_sizes: # Loop arund the sample sizes\n",
        "    res={}\n",
        "    for i in range(number_of_runs): # For each size we run it 3 times\n",
        "       Pos=random.sample(top_10(pos_freq, neg_freq, size),size) # generating the positive review (bag of words rep)\n",
        "       Neg= random.sample(top_10(neg_freq,pos_freq, size),size) #generating the negative reviews ( bag of words rep)\n",
        "       for name in  Names:\n",
        "        Classifying=Word_Classifier(Pos,Neg) # Train our word list classifier\n",
        "        score1=ConfusionMatrix(Classifying.classify_many(docs),labels).accuracy() # calculate the accuracy\n",
        "        res[name]=score1\n",
        "    results[size]=res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esNCFwj9aTRb"
      },
      "source": [
        "In the cell below, is the accuracy of our word classifier over the sample size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "lnJeboAYhgvm",
        "outputId": "b85de20e-f456-45e6-a1b8-a1a3941717c0"
      },
      "source": [
        "df=pd.DataFrame(results)\n",
        "df=df.transpose()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word Classifiers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.541667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.656667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.668333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.641667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>0.663333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>0.665000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>0.661667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>0.661667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Word Classifiers\n",
              "1            0.541667\n",
              "10           0.656667\n",
              "50           0.668333\n",
              "100          0.641667\n",
              "200          0.663333\n",
              "400          0.665000\n",
              "600          0.661667\n",
              "700          0.661667"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIHdFKMkakvy"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "After, we have plotted our accuracy over the sample size. From the graph below we could clearly see that the accuracy increases when we increase the amount of the training data. When it reach the 100 training data there is a slight decrease, but after it increase and it keeps decreasing very slowly ( probably a decimal point decrease). We can conclude that the increase in the training size could help but not consistent, in contrast, after a certain point it starts to decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "PFnF11DslLX3",
        "outputId": "a67eb287-cd04-4f1e-851e-2326b2b5199f"
      },
      "source": [
        "#Plotting the accuracy over the sample size\n",
        "ax = df.plot(kind=\"line\",title=\"Accuracy Vs sample size\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_xlabel(\"Sample Size\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Sample Size')"
            ]
          },
          "metadata": {},
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_cn10vwcEth"
      },
      "source": [
        "**Word Classifier VS Naive Bayes Algorithm**\n",
        "\n",
        "I would recommend the Naive Bayes algorithm oveer the word classifier, as we could clearly see that the Naive Bayes outpreform the word classifier in most of the training data sizes. Even though, the word classifier was better slightly than the Naive bayes but it is not consistent and increasing the amount of training data doesnt help much unlike the Naive bayes algorithm where we could see a massive improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C8M9Nw9ZaPJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPAqN1aGmBrJ",
        "outputId": "943bbcd5-ad2b-40ec-c060-f950eda857dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34rdlS_iPov6",
        "outputId": "b5a1e35f-98f4-4ac6-affc-3c6868d76f0e"
      },
      "source": [
        "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
        "##Running it before providing any answers shows that the questions have a word count of 437\n",
        "\n",
        "import io\n",
        "from nbformat import current\n",
        "\n",
        "filepath='/content/drive/My Drive/PG2021/NLassignment2021.ipynb'\n",
        "#filepath=\"NLassignment2021.ipynb\"\n",
        "question_count=437\n",
        "\n",
        "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "word_count = 0\n",
        "for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type == \"markdown\":\n",
        "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
        "print(\"Submission length is {}\".format(word_count-question_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission length is 1391\n"
          ]
        }
      ]
    }
  ]
}